{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S4b_train = np.load('S4b_train.npz')\n",
    "X11b_train = np.load('X11b_train.npz')\n",
    "S4b_test = np.load('S4b_test.npz')\n",
    "X11b_test = np.load('X11b_test.npz')\n",
    "\n",
    "train_data = np.concatenate((S4b_train['signal'], X11b_train['signal']), axis=0)\n",
    "train_label = np.concatenate((S4b_train['label'], X11b_train['label']), axis=0)\n",
    "test_data = np.concatenate((S4b_test['signal'], X11b_test['signal']), axis=0)\n",
    "test_label = np.concatenate((S4b_test['label'], X11b_test['label']), axis=0)\n",
    "\n",
    "train_label = train_label - 1\n",
    "test_label = test_label -1\n",
    "train_data = np.transpose(np.expand_dims(train_data, axis=1), (0, 1, 3, 2))\n",
    "test_data = np.transpose(np.expand_dims(test_data, axis=1), (0, 1, 3, 2))\n",
    "\n",
    "mask = np.where(np.isnan(train_data))\n",
    "train_data[mask] = np.nanmean(train_data)\n",
    "\n",
    "mask = np.where(np.isnan(test_data))\n",
    "test_data[mask] = np.nanmean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(train_data).float()\n",
    "y_train = torch.from_numpy(train_label).float()\n",
    "\n",
    "X_test = torch.from_numpy(test_data).float()\n",
    "y_test = torch.from_numpy(test_label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of dataset: \n",
      "\n",
      "\n",
      "[[[ 5.48605805  4.4517016   4.09471132 ... -0.91535741 -3.20223105\n",
      "   -1.53627641]\n",
      "  [ 5.52571777  4.45307401  4.84520693 ... -6.9935455  -5.60505926\n",
      "   -1.15580007]]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Example of dataset: \")\n",
    "print (\"\\n\")\n",
    "print (train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 trials / 1 person / 2 hands / 750 with values\n"
     ]
    }
   ],
   "source": [
    "print (str(len(train_data))+\" trials / \"+str(len(train_data[0]))+\\\n",
    "       \" person / \"+str(len(train_data[0][0]))+\" hands / \"+str(len(train_data[0][0][0]))+\" with values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGNet with ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet_ELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet_ELU, self).__init__()\n",
    "        # Layer 1 \n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 51), stride=(1,1),padding = (0,25), bias=False),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1 , affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(2,1),stride=(1,1),groups=16,bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4),padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # Layer 3\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=(1,15),stride=(1,1),padding=(0,7),bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8), stride=(1,8), padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # FC Layer\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(in_features=736, out_features=1, bias=True),\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.firstconv(x)\n",
    "        # Layer 2\n",
    "        x = self.depthwiseConv(x)\n",
    "        # Layer 3\n",
    "        x = self.separableConv(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classify(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "net_ELU = EEGNet_ELU()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_ELU.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGNet with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet_ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet_ReLU, self).__init__()\n",
    "        # Layer 1 \n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 51), stride=(1,1),padding = (0,25), bias=False),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1 , affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(2,1),stride=(1,1),groups=16,bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4),padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # Layer 3\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=(1,15),stride=(1,1),padding=(0,7),bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8), stride=(1,8), padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # FC Layer\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(in_features=736, out_features=1, bias=True),\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.firstconv(x)\n",
    "        # Layer 2\n",
    "        x = self.depthwiseConv(x)\n",
    "        # Layer 3\n",
    "        x = self.separableConv(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classify(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "net_ReLU = EEGNet_ReLU()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_ReLU.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGNet with LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet_LeakyReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet_LeakyReLU, self).__init__()\n",
    "        # Layer 1 \n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 51), stride=(1,1),padding = (0,25), bias=False),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1 , affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(2,1),stride=(1,1),groups=16,bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4),padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # Layer 3\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=(1,15),stride=(1,1),padding=(0,7),bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8), stride=(1,8), padding=0),\n",
    "            nn.Dropout(p=0.25))\n",
    "        \n",
    "        # FC Layer\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(in_features=736, out_features=1, bias=True),\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.firstconv(x)\n",
    "        # Layer 2\n",
    "        x = self.depthwiseConv(x)\n",
    "        # Layer 3\n",
    "        x = self.separableConv(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classify(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "net_LeakyReLU = EEGNet_LeakyReLU()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_LeakyReLU.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(net, x, y):\n",
    "        running_loss = 0.0\n",
    "        batch_size = 32\n",
    "        for i in range(int(len(x)/batch_size)):\n",
    "            s = i * batch_size\n",
    "            e = i * batch_size + batch_size\n",
    "\n",
    "            inputs = x[s:e]\n",
    "            labels = y[s:e]\n",
    "\n",
    "\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = nn.MSELoss()\n",
    "\n",
    "            output = loss(outputs, labels)\n",
    "            output.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = running_loss + output.data\n",
    "        \n",
    "        return net.forward(x)\n",
    "            \n",
    "def train(net, x, y):\n",
    "        backward(net, x, y)\n",
    "        outputs = backward(net, x, y)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (ReLU) train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is:  0\n",
      "ACC is:  0.49166666666666664\n",
      "Epoch is:  30\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  60\n",
      "ACC is:  0.4888888888888889\n",
      "Epoch is:  90\n",
      "ACC is:  0.4898148148148148\n",
      "Epoch is:  120\n",
      "ACC is:  0.4962962962962963\n",
      "Epoch is:  150\n",
      "ACC is:  0.4888888888888889\n",
      "Epoch is:  180\n",
      "ACC is:  0.49444444444444446\n",
      "Epoch is:  210\n",
      "ACC is:  0.49444444444444446\n",
      "Epoch is:  240\n",
      "ACC is:  0.487962962962963\n",
      "Epoch is:  270\n",
      "ACC is:  0.49074074074074076\n",
      "Epoch is:  300\n",
      "ACC is:  0.4898148148148148\n"
     ]
    }
   ],
   "source": [
    "relu_epoch_result_to_plot = []\n",
    "relu_acc_result_to_plot_train = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_ReLU,X_train,y_train)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            relu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_train, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            relu_acc_result_to_plot_train.append(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (ReLU) test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is:  0\n",
      "ACC is:  0.4861111111111111\n",
      "Epoch is:  30\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  60\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  90\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  120\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  150\n",
      "ACC is:  0.4888888888888889\n",
      "Epoch is:  180\n",
      "ACC is:  0.4888888888888889\n",
      "Epoch is:  210\n",
      "ACC is:  0.4888888888888889\n",
      "Epoch is:  240\n",
      "ACC is:  0.4861111111111111\n",
      "Epoch is:  270\n",
      "ACC is:  0.48518518518518516\n",
      "Epoch is:  300\n",
      "ACC is:  0.4888888888888889\n"
     ]
    }
   ],
   "source": [
    "relu_epoch_result_to_plot = []\n",
    "relu_acc_result_to_plot = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_ReLU,X_test,y_test)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            relu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_test, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            relu_acc_result_to_plot.append(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (LeakyReLU) train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is:  0\n",
      "ACC is:  0.5648148148148148\n",
      "Epoch is:  30\n",
      "ACC is:  0.5592592592592592\n",
      "Epoch is:  60\n",
      "ACC is:  0.5601851851851852\n",
      "Epoch is:  90\n",
      "ACC is:  0.5805555555555556\n",
      "Epoch is:  120\n",
      "ACC is:  0.562037037037037\n",
      "Epoch is:  150\n",
      "ACC is:  0.5666666666666667\n",
      "Epoch is:  180\n",
      "ACC is:  0.5740740740740741\n",
      "Epoch is:  210\n",
      "ACC is:  0.5703703703703704\n",
      "Epoch is:  240\n",
      "ACC is:  0.5731481481481482\n",
      "Epoch is:  270\n",
      "ACC is:  0.5518518518518518\n",
      "Epoch is:  300\n",
      "ACC is:  0.562037037037037\n"
     ]
    }
   ],
   "source": [
    "leakyrelu_epoch_result_to_plot = []\n",
    "leakyrelu_acc_result_to_plot_train = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_LeakyReLU,X_train,y_train)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            leakyrelu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_train, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            leakyrelu_acc_result_to_plot_train.append(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (LeakyReLU) test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is:  0\n",
      "ACC is:  0.5305555555555556\n",
      "Epoch is:  30\n",
      "ACC is:  0.5416666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1e7a3aa1d4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m301\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# loop over the dataset multiple times\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_LeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m30\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-00d1f991a6ee>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, x, y)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-00d1f991a6ee>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(net, x, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "leakyrelu_epoch_result_to_plot = []\n",
    "leakyrelu_acc_result_to_plot = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_LeakyReLU,X_test,y_test)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            leakyrelu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_test, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            leakyrelu_acc_result_to_plot.append(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (ELU) train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_epoch_result_to_plot = []\n",
    "elu_acc_result_to_plot_train = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_ELU,X_train,y_train)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            elu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_train, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            elu_acc_result_to_plot_train.append(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練model (ELU) test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_epoch_result_to_plot = []\n",
    "elu_acc_result_to_plot = []\n",
    "for epoch in range(301):  # loop over the dataset multiple times\n",
    "            \n",
    "        result = train(net_ELU,X_test,y_test)\n",
    "        \n",
    "        if epoch%30 == 0:\n",
    "            print (\"Epoch is: \", epoch)\n",
    "            elu_epoch_result_to_plot.append(epoch)\n",
    "            ACC = accuracy_score(y_test, np.round(result.data))\n",
    "            print (\"ACC is: \", ACC)\n",
    "            elu_acc_result_to_plot.append(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Activation function comparision(EEGNet )')\n",
    "plt.plot(relu_epoch_result_to_plot, relu_acc_result_to_plot, color='green', label='relu_test')\n",
    "plt.plot(relu_epoch_result_to_plot, relu_acc_result_to_plot_train, color='cyan', label='relu_train')\n",
    "plt.plot(leakyrelu_epoch_result_to_plot, leakyrelu_acc_result_to_plot,  color='skyblue', label='leaky_relu_test')\n",
    "plt.plot(leakyrelu_epoch_result_to_plot, leakyrelu_acc_result_to_plot_train,  color='blue', label='leaky_relu_train')\n",
    "plt.plot(elu_epoch_result_to_plot, elu_acc_result_to_plot, color='red', label='elu_test')\n",
    "plt.plot(elu_epoch_result_to_plot, elu_acc_result_to_plot_train, color='pink', label='elu_train')\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
